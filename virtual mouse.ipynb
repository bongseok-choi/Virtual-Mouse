{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "class handDetector():\n",
    "    def __init__(self, mode=False, maxHands=2, modelComplexity=1, detectionCon=0.5, trackCon=0.5):\n",
    "        self.lmList = []\n",
    "        self.results = None\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.modelComplex = modelComplexity\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands, self.modelComplex, self.detectionCon, self.trackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "\n",
    "    def findHands(self, img, draw=True):\n",
    "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(rgb_img)\n",
    "        # print(results.multi_hand_landmarks)\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def findPosition(self, img, handNo=0, draw=True):\n",
    "        xList = []\n",
    "        yList = []\n",
    "        bbox = []\n",
    "        self.lmList = []\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                # print(id, lm)\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                xList.append(cx)\n",
    "                yList.append(cy)\n",
    "                # print(id, cx, cy)\n",
    "                self.lmList.append([id, cx, cy])\n",
    "\n",
    "                if draw:\n",
    "                    cv2.circle(img, (cx, cy), 6, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "            xmin, xmax = min(xList), max(xList)\n",
    "            ymin, ymax = min(yList), max(yList)\n",
    "            bbox = xmin, ymin, xmax, ymax\n",
    "\n",
    "            if draw:\n",
    "                cv2.rectangle(img, (bbox[0]-20, bbox[1]-20), (bbox[2]+20, bbox[3]+20), (0, 255, 0), 2)\n",
    "\n",
    "        return self.lmList, bbox\n",
    "\n",
    "    def fingersUp(self):\n",
    "        fingers = []\n",
    "        # Thumb\n",
    "        if self.lmList[self.tipIds[0]][1] < self.lmList[self.tipIds[0] - 1][1]:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "        # 4 Fingers\n",
    "        for id in range(1, 5):\n",
    "            if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "        return fingers\n",
    "\n",
    "    def findDistance(self, p1, p2, img, draw=True):\n",
    "        x1, y1 = self.lmList[p1][1:]\n",
    "        x2, y2 = self.lmList[p2][1:]\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "        if draw:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (0, 255, 255), 3)\n",
    "            cv2.circle(img, (x1, y1), 6, (0, 255, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x2, y2), 6, (0, 255, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (cx, cy), 6, (0, 255, 255), cv2.FILLED)\n",
    "\n",
    "        length = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        return length, img, [x1, y1, x2, y2, cx, cy]\n",
    "\n",
    "    def findAngle(self, p1, p2, p3, img, draw=True):\n",
    "        # Get the landmarks\n",
    "        x1, y1 = self.lmList[p1][1:]\n",
    "        x2, y2 = self.lmList[p2][1:]\n",
    "        x3, y3 = self.lmList[p3][1:]\n",
    "        # Calculate the Angle\n",
    "        angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "        if angle < 0:\n",
    "            angle += 360\n",
    "\n",
    "        # print(angle)\n",
    "\n",
    "        # Draw\n",
    "        if draw:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 3)\n",
    "            cv2.line(img, (x3, y3), (x2, y2), (255, 255, 255), 3)\n",
    "            cv2.circle(img, (x1, y1), 15, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x1, y1), 15, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x2, y2), 15, (0, 0, 255), cv2.FILLED)\n",
    "            # cv2.putText(img, str(int(angle)), (x2 - 50, y2 + 50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "\n",
    "        return angle\n",
    "\n",
    "def main():\n",
    "    pTime = 0\n",
    "    cTime = 0\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector = handDetector()\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img = detector.findHands(img)\n",
    "        lmList, bbox = detector.findPosition(img)\n",
    "        if len(lmList) != 0:\n",
    "            print(lmList[4])\n",
    "\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "\n",
    "        cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                    (255, 0, 255), 3)\n",
    "\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d958b31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 1080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 25\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindHands\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     lmList, bbox \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mfindPosition(img)\n\u001b[0;32m     27\u001b[0m     output \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\hand_detector.py:24\u001b[0m, in \u001b[0;36mhandDetector.findHands\u001b[1;34m(self, img, draw)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindHands\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     23\u001b[0m     rgb_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# print(results.multi_hand_landmarks)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m   \u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    362\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    363\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import hand_detector as hd\n",
    "import pyautogui\n",
    "\n",
    "\n",
    "wCam, hCam = 640, 480\n",
    "frameR = 100\n",
    "smoothening = 7\n",
    "\n",
    "pTime = 0\n",
    "plocX, plocY = 0, 0\n",
    "clocX, clocY = 0, 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, wCam)\n",
    "cap.set(4, hCam)\n",
    "detector = hd.handDetector(detectionCon=0.7)\n",
    "wScr, hScr = pyautogui.size()\n",
    "print(wScr, hScr)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = detector.findHands(img)\n",
    "    lmList, bbox = detector.findPosition(img)\n",
    "    output = img.copy()\n",
    "\n",
    "    if len(lmList) != 0:\n",
    "        # print(lmList[4], lmList[8])\n",
    "        x1, y1 = lmList[8][1:]\n",
    "        x2, y2 = lmList[12][1:]\n",
    "\n",
    "        fingers = detector.fingersUp()\n",
    "        # print(fingers)\n",
    "        cv2.rectangle(img, (frameR, frameR), (wCam - frameR, hCam - frameR), (205, 250, 255), -1)\n",
    "        img = cv2.addWeighted(img, 0.5, output, 1 - .5, 0, output)\n",
    "\n",
    "        # Only Index Finger : Moving Mode\n",
    "        if fingers[1] == 1 and fingers[2] == 0:\n",
    "            # Convert Coordinates\n",
    "            x3 = np.interp(x1, (frameR, wCam - frameR), (0, wScr))\n",
    "            y3 = np.interp(y1, (frameR, hCam - frameR), (0, hScr))\n",
    "\n",
    "            # Smoothen Values\n",
    "            clocX = plocX + (x3 - plocX) / smoothening\n",
    "            clocY = plocY + (y3 - plocY) / smoothening\n",
    "\n",
    "            # Move Mouse\n",
    "            pyautogui.moveTo(wScr - clocX, clocY)\n",
    "            cv2.circle(img, (x1, y1), 6, (255, 28, 0), cv2.FILLED)\n",
    "            plocX, plocY = clocX, clocY\n",
    "            # cv2.putText(img, 'Moving Mode', (20, 50), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "\n",
    "        # Both Index and middle fingers are up : Clicking Mode\n",
    "        if fingers[1] == 1 and fingers[2] == 1:\n",
    "            # Find distance between fingers\n",
    "            length, img, lineInfo = detector.findDistance(8, 12, img)\n",
    "\n",
    "            # Click mouse if distance short\n",
    "            if length < 40:\n",
    "                cv2.circle(img, (lineInfo[4], lineInfo[5]), 6, (0, 255, 0), cv2.FILLED)\n",
    "                # cv2.putText(img, 'Click!!', (20, 50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "                pyautogui.click()\n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    cv2.imshow(\"Vitual mouse monitor\", cv2.flip(img, 1))\n",
    "    cv2.setWindowProperty(\"Vitual mouse monitor\", cv2.WND_PROP_TOPMOST, 1)\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
